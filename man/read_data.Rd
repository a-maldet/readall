% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/read_data.R
\name{read_data}
\alias{read_data}
\alias{read_data_fwf}
\alias{read_data_dsv}
\alias{read_data_excel}
\alias{read_data_sas}
\title{Read FWF, DSV or EXCEL data files}
\usage{
read_data(file_definition)

read_data_fwf(
  file_path,
  specification_files = NULL,
  cols = NULL,
  col_names = NULL,
  col_types = NULL,
  col_start = NULL,
  col_end = NULL,
  col_widths = NULL,
  sep_width = 0,
  skip_rows = 0,
  na = "",
  decimal_mark = ".",
  big_mark = ",",
  trim_ws = TRUE,
  n_max = Inf,
  encoding = "latin1",
  to_lower = TRUE,
  adapters = new_adapters(),
  cols_keep = TRUE,
  extra_col_name = NULL,
  extra_col_val = NULL,
  extra_col_file_path = FALSE,
  ...
)

read_data_dsv(
  file_path,
  specification_files = NULL,
  cols = NULL,
  col_names = NULL,
  col_types = NULL,
  sep = ";",
  header = TRUE,
  skip_rows = 0,
  na = "",
  decimal_mark = ".",
  big_mark = ",",
  trim_ws = TRUE,
  n_max = Inf,
  encoding = "latin1",
  to_lower = TRUE,
  rename_cols = FALSE,
  adapters = new_adapters(),
  cols_keep = TRUE,
  extra_col_name = NULL,
  extra_col_val = NULL,
  extra_col_file_path = FALSE,
  ...
)

read_data_excel(
  file_path,
  specification_files = NULL,
  range = NULL,
  sheet = NULL,
  cols = NULL,
  col_names = NULL,
  col_types = NULL,
  header = TRUE,
  skip_rows = 0,
  na = "",
  trim_ws = TRUE,
  n_max = Inf,
  to_lower = TRUE,
  rename_cols = FALSE,
  adapters = new_adapters(),
  cols_keep = TRUE,
  extra_col_name = NULL,
  extra_col_val = NULL,
  extra_col_file_path = FALSE,
  ...
)

read_data_sas(
  file_path,
  specification_files = NULL,
  skip_rows = 0,
  n_max = Inf,
  encoding = NULL,
  to_lower = TRUE,
  rename_cols = FALSE,
  retype_cols = FALSE,
  adapters = new_adapters(),
  cols_keep = TRUE,
  extra_col_name = NULL,
  extra_col_val = NULL,
  extra_col_file_path = FALSE,
  ...
)
}
\arguments{
\item{file_definition}{A file_definitionuration object, holds all informations needed for
reading the data. This object can be created with one of the following
functions:
\itemize{
\item \code{new_file_definition()}: For reading FWF, DSV or EXCEL files
\item \code{new_file_definition_fwf()}: For reading FWF files
\item \code{new_file_definition_dsv()}: For reading DSV files
\item \code{new_file_definition_excel()}: For reading EXCEL files
}}

\item{file_path}{A string holding the path to the data file.}

\item{specification_files}{An optional character vector holding the paths
to the files, where the file structure is described.}

\item{cols}{An optional list argument, holding the column definitions.
This argument can be used instead of the arguments
\code{col_names}, \code{col_types}, \code{col_start}, \code{col_end}, \code{col_widths}, in order
to define the column structure. If the argument \code{cols} is used, then
non of the \verb{col_*} argument are allowed. If so, the \code{cols} argument
has the following structure: It is list, where each list entry fully describes
a single column. Each list entry must have the same subselection of the
following possible list entries:
\itemize{
\item \code{type}: (obligatoric) A string value defining the data type of the column.
The following values are allowed: \code{"character"}, \code{"logical"}, \code{"integer"},
\code{"numeric"} and \code{"NULL"} (for skipping this column). In the case of SAS files
the \code{type} information can be omitted, since the data type information
is stored in the SAS data files, but the argument \code{type} can still
be useful in order to check that the read data column have the expected
data type. For SAS-Files this check is done automatically after reading
the data with \code{\link[=read_data]{read_data()}}.
\item \code{name}: (optional) A string holding the column name.
\item \code{start}: (optional) A number holding the position of the first character of the column.
\item \code{end}: (optional) A number holding the position of the last character of the column.
\item \code{width} (optional) A numeric holding the number characters of the column.
\item \code{col_meta}: (optional) A \link[=new_col_meta]{col_meta} class object, holding some
meta information for the specific column (column description,
possible column values + descriptions of possible column values).
For details see section \strong{meta information}.
}}

\item{col_names}{An optional character vector holding the names of the columns.
If omitted, then the strings \code{"x1"}, \code{"x2"}, ... will be used.
In the case of DSV or EXCEL files: If the argument \code{header} is
set to \code{TRUE}, then the column names given
in the data header will be used instead. If \code{col_names} is also supplied,
then the column names given in the DSV, EXCEL or SAS file will be compared
with the names given in \code{col_names}. Sometimes it is useful, to have the
column names to be automatically transformed to lower case (directly after
reading the date, but before comparing the column names). This can be
achieved by setting \code{to_lower = TRUE}.
Generally, the argument \code{cols} can be used instead, in order to define
the column names. If the argument \code{cols} is not \code{NULL},
then the argument \code{col_names} must be omitted.}

\item{col_types}{A character vector defining the data types for each column.
The following strings are allowed: \code{"character"}, \code{"logical"},
\code{"integer"}, \code{"numeric"} and \code{"NULL"} (for skipping this column).
Generally, the argument \code{cols} can be used instead, in order to define
the column types. If the argument \code{cols} is not \code{NULL},
then the argument \code{col_types} must be omitted. In the case of SAS files
the \code{col_types} information can be omitted, since the data type information
is stored in the SAS data files, but the argument \code{col_types} can still
be useful in order to check the read data files, if the data types are
as expected. For SAS-Files this check is done automatically after reading
the data with \code{\link[=read_data]{read_data()}}}

\item{col_start}{An optional numeric vector holding the positions of the first character
of each column.
Generally, the argument \code{cols} can be used instead, in order to define
the column start positions. If the argument \code{cols} is not \code{NULL},
then the argument \code{col_start} must be omitted.}

\item{col_end}{An optional numeric vector holding the positions of the last character
of each column. The last vector entry (for the most right column)
is the only entry that can be \code{NA}. In this case, the most right
cells are always read till the new line character.
Generally, the argument \code{cols} can be used instead, in order to define
the column end positions. If the argument \code{cols} is not \code{NULL},
then the argument \code{col_end} must be omitted.}

\item{col_widths}{An optional numeric vector holding the numbers of characters
of each column.
Generally, the argument \code{cols} can be used instead, in order to define
the column widths. If the argument \code{cols} is not \code{NULL},
then the argument \code{col_widths} must be omitted.}

\item{sep_width}{An optional number, defining the number of characters
between each column (often \code{0}).}

\item{skip_rows}{The number of rows to be skipped. In the case of DSV or
EXCEL files: If the argument \code{header} is set to \code{TRUE}, then the
first row is always assumed to be the header row.}

\item{na}{A string representing missing values in the data file.}

\item{decimal_mark}{A character, defining the decimal separator in numeric
columns. Only the strings \code{"."} and \code{","} are allowed.}

\item{big_mark}{A character, defining the thousands separator in numeric
columns. Only the strings \code{"."} and \code{","} are allowed.}

\item{trim_ws}{A logical value, defining if the character values should
be stipped of all leading and trailing white spaces.}

\item{n_max}{A number, defining the maximum number of rows to be
read. If \code{n_max = Inf}, then  all available rows will be read.}

\item{encoding}{A string, defining which encoding should be assumed when
reading the data file. The following valuels are allowed:
\itemize{
\item \code{"UTF-8"}: For \emph{UTF-8} encoded files.
\item \code{"latin1"}: For \emph{ISO 8859-1} (also called \emph{Latin-1}) encoded files.
This encoding is almost the same as \emph{Windows-1252} (also called \emph{ANSI}).
They differ only in 32 symbol codes (special symbols that are rarely
used). In the case of SAS files, it is possible to set \code{encoding = NULL}.
In this case, the encoding defined in the SAS data file header
will be used.
}}

\item{to_lower}{A logical flag, defining if the names of the columns should
be transformed to lower case after reading the data set (by calling
\code{\link[=read_data]{read_data()}}). This transformation will be applied before comparing the
column names (in the case of SAS-Files or DSV- and EXCE-Files with
\code{header = TRUE}).
In the case of \code{new_file_definition()} the \code{to_lower} argument
overwrites the \code{to_lower} argument in the
\link[=new_file_structure_fwf]{file_structure} class object given in
\code{file_structure}. If \code{to_lower} is omitted, then the \code{file_structure}
class object remains unchanged.
In the case of \code{new_file_definition_fwf()}, \code{new_file_definition_dsv()}, \code{new_file_definition_excel()}
or \code{new_file_definition_sas()} the argument \code{to_lower} must either be \code{TRUE}
or \code{FALSE}.}

\item{adapters}{An optional list argument, holding a list of adapter functions
(See section \emph{adapters}).}

\item{cols_keep}{Either \code{TRUE} or a character vector.
If set to \code{TRUE}, then all columns of the data
are kept when calling \code{\link[=read_data]{read_data()}}.
If \code{cols_keep} character vector, then the values in \code{cols_keep} represent
the names of the columns, which are kept  when calling \code{\link[=read_data]{read_data()}}.}

\item{extra_col_name}{An optional string, which defines the column, which
will be added to the data set (after reading it with function \code{\link[=read_data]{read_data()}}).
Each entry of the column will have the single value given in \code{extra_col_val}.
For example: This column is useful when reading similar data files for
separate years (one could pass the current data set year to \code{extra_col_name}
and set \code{extra_col_name = "year"}).
If \code{extra_col_name} is omitted, no column will be added to the data set and
then \code{extra_col_val} must be omitted as well.
additional column with the column name, given in  \code{extra_col_name}.
If omitted, then no column will be added to the data set and the
argument \code{extra_col_name} must be omitted as well.}

\item{extra_col_val}{An optional value (any atomic type), which will be added
(after reading the data set with function \code{\link[=read_data]{read_data()}}) as an
additional column with the column name, given in  \code{extra_col_name}.
For example: This column is useful when reading similar data files for
separate years (one could pass the current data set year to \code{extra_col_name}
and set \code{extra_col_name = "year"}).
If omitted, then no column will be added to the data set and the
argument \code{extra_col_name} must be omitted as well.}

\item{extra_col_file_path}{Either \code{FALSE} or a string.
If set to \code{FALSE} no file-path-column will be added to the data set, when
calling \code{\link[=read_data]{read_data()}}.
If the argument \code{extra_col_file_path} is a string, then a column holding
the file path of the data file will be added to the read data set, when
calling \code{\link[=read_data]{read_data()}}. The string of \code{extra_col_file_path} will be used
as column name for this additional column.}

\item{...}{Additional function arguments for
\itemize{
\item \code{\link[readr:read_fwf]{readr::read_fwf()}} in case of FWF files
\item \code{\link[utils:read.table]{utils::read.delim()}} in case of DSV files
\item \code{\link[readxl:read_excel]{readxl::read_excel()}} in case of EXCEL files
}}

\item{sep}{A string holding the column deliminator symbol.}

\item{header}{A logical value, which defines if the first row contains
the data headers. If set to \code{TRUE}, then the names given in the data
header will be used as column names instead.}

\item{rename_cols}{A logical value, which defines if the columns given in
the data file should be overwritten by the columns given in argument
\code{col_names}. If \code{col_names} is not given, then \code{rename_cols} has no
effect.}

\item{range}{An optional string, holding an EXCEL range string, defining the
data range in the spread sheet. If \code{header} is set to \code{TRUE}, then
the range must include a header row.}

\item{sheet}{A string or an integer number:
\itemize{
\item string: The value defines the name of the sheet, which should be read.
\item integer: The value defines the position of the sheet, which should be read.
(start counting with \code{1}).
}}

\item{retype_cols}{A logical value, which defines if the types of the
columns given in SAS file changed to the types given in the
\code{col_types} argument. If \code{col_types} is not given, then \code{retype_cols} has no
effect.}
}
\value{
A data.frame holding the read data.
}
\description{
The functions \code{read_data()}, \code{read_data_fwf()}, \code{read_data_dsv()} and
\code{read_data_excel()} are all used in order to read FWF, DSV or EXCEL data files.
The function \code{read_data()} is the heart of the \code{readall} package and it
only requires the user to pass a single function argument
(a \link[=new_file_definition]{file_definition} class object), holding all
needed file information in order to read the data file. By instead passing a
\link[=new_file_collection]{file_collection} class object into \code{read_data()}, it is
also possible to read multiple data files at once and store the concatenated
data sets into a single data.frame.
The functions \code{read_data_fwf()}, \code{read_data_dsv()} and \code{read_data_excel()}
are less flexible, but have a more common structure, since this functions
do not use \link[=new_file_definition]{file_definition} class objects, but require the user
to pass in all file information directly as function arguments.
}
\details{
The function \code{read_data()} can either read a single data file and
return a data.frame or it can read multiple data files at once and return
the concatenated data sets as a single data.frame.
\code{read_data()} can read the following data file types:
\itemize{
\item \code{FWF}: Fixed width files. This files are text files, where the data is
stored in columns, that have a fixed character width.
\item \code{DSV}: Delimiter-separated value file. This files are text files, where
the data is stored in columns that are separated by a delimiter character.
\item \code{EXCEL}: An excel file holding the data.
}

In order to read a single file with \code{read_data()}
a \link[=new_file_definition]{file_definition} class object must be
passed into the function argument \code{file_definition}.
This \link[=new_file_definition]{file_definition} class objects
contain all information needed for reading a specific data file.
When calling \code{read_data(file_definition)} where \code{file_definition} is a \link[=new_file_definition]{file_definition} class
object, the following tasks will be executed:
\itemize{
\item reading the data file specified in \code{file_definition} and storing the data to a data.frame
\item if the argument \code{to_lower} was set to \code{TRUE}, then replace all column
names of the read data set by its lower case version.
\item if the column names where read from the data file and the column names
are given by the \code{col_names} argument, then compare the read column
names with the column names given in \code{col_names} and print a warning in
case of discrepancies.
\item in the case of SAS-files: If the argument \code{col_types} was given as well,
then compare the read data types of the data columns with the
data types given in \code{col_types} and print a warning in
case of discrepancies.
\item modifying the resulting data.frame by consecutively applying all adapter functions
stored in the adapter function list argument \code{file_definition$adapters}.
For details see section \emph{adapters}
\item Optionally adding a column with value \code{file_definition$extra_col_val} and column name
\code{file_definition$extra_col_name}. For details see \code{\link[=new_file_definition]{new_file_definition()}}
\item Optionally adding a character column holding the path of the read data file
with column name defined in \code{file_definition$extra_col_file_path}.
\item If \code{file_definition$cols_keep} is not \code{NULL}, then only the columns defined in
\code{file_definition$cols_keep} will be kept. If the attribute is \code{NULL} then
all columns will be kept.
\item Finally the resulting data.frame will be returned.
}

In order to read multiple data files at once and automatically concatenate
the resulting data.frames into a single data.frame, you need to create a
list of \verb{[file_definition][new_file_definition()]} class objects first by using the function
\code{\link[=new_file_collection]{new_file_collection()}}.
Each list entry holds the meta data of a different data file.
When \code{read_data()} is applied on a \link[=new_file_collection]{file_collection} class
object, then the following tasks will be executed:
\itemize{
\item loop through the list apply \code{read_data()} on every list
entry. Since these entries are \link[=new_file_definition]{file_definition} class objects, the
tasks of reading single data files (as described above) will be executed
for each list entry.
\item concatenate all resulting data.frames into a single data.frame.
}
}
\section{File types}{

The function \code{\link[=read_data]{read_data()}} can read read four different types of data
\itemize{
\item \code{FWF}: Fixed width files. This files are text files, where the data is
stored in columns, that have a fixed character width.
\item \code{DSV}: Delimiter-separated value file. This files are text files, where
the data is stored in columns that are separated by a delimiter character.
\item \code{EXCEL}: An excel file holding the data.
\item \code{SAS}: A SAS file holding the data.

In order to read a data file with the function \code{\link[=read_data]{read_data()}},
it is useful to create a \link[=new_file_definition_fwf]{file_definitionuration} or
\link[=new_file_structure_fwf]{file_structure} class object,
holding all needed data file file_structures:
\itemize{
\item \code{\link[=new_file_definition_fwf]{new_file_definition_fwf()}} or \code{\link[=new_file_structure_fwf]{new_file_structure_fwf()}} for \code{FWF} files
\item \code{\link[=new_file_definition_dsv]{new_file_definition_dsv()}} or \code{\link[=new_file_structure_dsv]{new_file_structure_dsv()}} for \code{DSV} files
\item \code{\link[=new_file_definition_excel]{new_file_definition_excel()}} or \code{\link[=new_file_structure_excel]{new_file_structure_excel()}} for \code{Excel} files
\item \code{\link[=new_file_definition_sas]{new_file_definition_sas()}} or \code{\link[=new_file_structure_sas]{new_file_structure_sas()}} for \code{SAS} files
}
}
}

\section{difference file_structure/file_definition/file_collection}{

The goal of the package \code{readall} is it to read data files. For this
purpose the package offers three different class objects in order to
store meta data about the data files:
\itemize{
\item \link[=new_file_structure_fwf]{file_structure} class objects: Objects of this
class can be used in order to define
all file type specific information (e.g. column positions,
column names, column types, deliminator symbols, rows to skip etc.).
The idea is, that one \code{file_structure} object may valid for several files
and therefore be used to read multiple data files.
\item \link[=new_file_definition]{file_definition} class objects: Objects of this class type
contain all informations in order to read a single specific data file
(path to the data file, file \link[=new_file_structure_fwf]{file_structure} etc.).
A \link[=new_file_definition]{file_definition} class object contains a
\link[=new_file_structure_fwf]{file_structure}, which holds all file type
specific information, but also other informations that are only valid
for this specific file.
\item \link[=new_file_collection]{file_collection} class objects: A
\link[=new_file_collection]{file_collection} class object is simply a list holding
multiple \link[=new_file_definition]{file_definition} class objects.
A \link[=new_file_collection]{file_collection} class object
can be used in order to read several data files at once and concatenate
the data into a single data.frame.
}
}

\section{adapters}{

An adapter function is a function that takes a data.frame as input argument
and returns a modified version of this data.frame.
The adapter functions are stored in an \link[=new_adapters]{adapters}
class object, which is a special list that contains all adapter functions
and a description text of each function. This class objects can be
created by using the function \code{\link[=new_adapters]{new_adapters()}}.
The \link[=new_adapters]{adapters} class objects can be added to a
\link[=new_file_structure_fwf]{file_structure} or a
\link[=new_file_definition]{file_definition} or a \link[=new_file_collection]{file_collection} class object.
After reading a data file (by calling \link[=read_data]{read_data(file_definition)})
all adapter functions listed in the \code{adapters} argument of the
file_definition]\code{\link[=new_file_definition]{new_file_definition()}} class object
will be applied consecutively to the loaded data set.
Adapter functions can be added to an existing
\link[=new_file_structure_fwf]{file_structure} or a \link[=new_file_definition]{file_definition} or
a \link[=new_file_collection]{file_collection} class
object by using the function \code{\link[=add_adapters]{add_adapters()}}.
Adapter functions can be used for several tasks:
\itemize{
\item adapt the data sets in such a way that they can be concatenated for
mutliple years
\item compute new variables from existing variables
\item fix errors in variables
\item transform the values of a variable of an older data set, such that it
complies with a newer variable definition
}
}

